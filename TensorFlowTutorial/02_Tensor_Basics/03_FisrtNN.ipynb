{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Neural Net\n",
    "# Train, evaluate, and predict with the model\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# normalize: 0,255 -> 0,1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10),\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# another way to build the Sequential model:\n",
    "#model = keras.models.Sequential()\n",
    "#model.add(keras.layers.Flatten(input_shape=(28,28))\n",
    "#model.add(keras.layers.Dense(128, activation='relu'))\n",
    "#model.add(keras.layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 - 1s - loss: 0.3279 - accuracy: 0.9069 - 1s/epoch - 1ms/step\n",
      "Epoch 2/5\n",
      "938/938 - 1s - loss: 0.3134 - accuracy: 0.9105 - 1s/epoch - 1ms/step\n",
      "Epoch 3/5\n",
      "938/938 - 1s - loss: 0.3021 - accuracy: 0.9138 - 1s/epoch - 1ms/step\n",
      "Epoch 4/5\n",
      "938/938 - 1s - loss: 0.2925 - accuracy: 0.9159 - 1s/epoch - 1ms/step\n",
      "Epoch 5/5\n",
      "938/938 - 1s - loss: 0.2846 - accuracy: 0.9182 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29bde254dc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, shuffle = True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 0s - loss: 0.2737 - accuracy: 0.9226 - 286ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27367186546325684, 0.9225999712944031]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "model.evaluate(x_test, y_test, batch_size = batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[7.7841818e-05 1.7397545e-08 9.5210940e-05 1.6074878e-03 5.9363515e-07\n",
      " 3.8044425e-05 5.5559561e-09 9.9720287e-01 1.2846308e-05 9.6509903e-04], shape=(10,), dtype=float32)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "\n",
    "# 1. option: build new model with Softmax layer\n",
    "probability_model = keras.models.Sequential([\n",
    "    model, \n",
    "    keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "predictions = probability_model(x_test)\n",
    "pred0 = predictions[0]\n",
    "print(pred0)\n",
    "\n",
    "# use np.argmax to get label with highest probability\n",
    "label0 = np.argmax(pred0)\n",
    "print(label0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[7.7841818e-05 1.7397545e-08 9.5210940e-05 1.6074878e-03 5.9363515e-07\n",
      " 3.8044425e-05 5.5559561e-09 9.9720287e-01 1.2846308e-05 9.6509903e-04], shape=(10,), dtype=float32)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# 2. option: original model + nn.softmax, call model(x)\n",
    "predictions = model(x_test)\n",
    "predictions = tf.nn.softmax(predictions)\n",
    "pred0 = predictions[0]\n",
    "print(pred0)\n",
    "label0 = np.argmax(pred0)\n",
    "print(label0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[7.7841745e-05 1.7397545e-08 9.5210846e-05 1.6074878e-03 5.9363515e-07\n",
      " 3.8044425e-05 5.5559455e-09 9.9720287e-01 1.2846308e-05 9.6509862e-04], shape=(10,), dtype=float32)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# 3. option: original model + nn.softmax, call model.predict(x)\n",
    "predictions = model.predict(x_test, batch_size=batch_size)\n",
    "predictions = tf.nn.softmax(predictions)\n",
    "pred0 = predictions[0]\n",
    "print(pred0)\n",
    "label0 = np.argmax(pred0)\n",
    "print(label0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# call argmax for multiple labels\n",
    "pred05s = predictions[0:5]\n",
    "print(pred05s.shape)\n",
    "label05s = np.argmax(pred05s, axis=1)\n",
    "print(label05s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
