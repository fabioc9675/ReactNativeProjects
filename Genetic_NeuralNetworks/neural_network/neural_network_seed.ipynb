{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of my first neural network\n",
    "\n",
    "## Feed Forward Back Propagation\n",
    "\n",
    "se creará una red neuronal feed forward back propagation con una capa de entrada, una capa oculta y una capa de salida\n",
    "\n",
    "retorpropagacion: https://www.youtube.com/watch?v=tIeHLnjs5U8\n",
    "\n",
    "backpropagation: https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd\n",
    "\n",
    "### Author\n",
    "\n",
    "Fabian Castaño [GitHub](https://www.github.com/fabioc9675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importacion de librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">var_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">var_2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">var_6</th>\n",
       "      <th colspan=\"8\" halign=\"left\">var_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salida</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>14.334429</td>\n",
       "      <td>1.215704</td>\n",
       "      <td>11.23</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>14.355</td>\n",
       "      <td>15.0450</td>\n",
       "      <td>17.08</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.294286</td>\n",
       "      <td>...</td>\n",
       "      <td>3.30100</td>\n",
       "      <td>6.685</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.087214</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>4.519</td>\n",
       "      <td>4.9245</td>\n",
       "      <td>5.0940</td>\n",
       "      <td>5.22350</td>\n",
       "      <td>5.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>18.334286</td>\n",
       "      <td>1.439496</td>\n",
       "      <td>15.38</td>\n",
       "      <td>17.3300</td>\n",
       "      <td>18.720</td>\n",
       "      <td>19.1375</td>\n",
       "      <td>21.18</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.135714</td>\n",
       "      <td>...</td>\n",
       "      <td>4.43600</td>\n",
       "      <td>6.682</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.020600</td>\n",
       "      <td>0.253934</td>\n",
       "      <td>5.144</td>\n",
       "      <td>5.8775</td>\n",
       "      <td>5.9815</td>\n",
       "      <td>6.18775</td>\n",
       "      <td>6.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>11.873857</td>\n",
       "      <td>0.723004</td>\n",
       "      <td>10.59</td>\n",
       "      <td>11.2625</td>\n",
       "      <td>11.835</td>\n",
       "      <td>12.4250</td>\n",
       "      <td>13.37</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13.247857</td>\n",
       "      <td>...</td>\n",
       "      <td>5.46725</td>\n",
       "      <td>8.456</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.116400</td>\n",
       "      <td>0.162068</td>\n",
       "      <td>4.745</td>\n",
       "      <td>5.0020</td>\n",
       "      <td>5.0915</td>\n",
       "      <td>5.22850</td>\n",
       "      <td>5.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_1                                                               \\\n",
       "       count       mean       std    min      25%     50%      75%    max   \n",
       "salida                                                                      \n",
       "1       70.0  14.334429  1.215704  11.23  13.7500  14.355  15.0450  17.08   \n",
       "2       70.0  18.334286  1.439496  15.38  17.3300  18.720  19.1375  21.18   \n",
       "3       70.0  11.873857  0.723004  10.59  11.2625  11.835  12.4250  13.37   \n",
       "\n",
       "       var_2             ...    var_6        var_7                             \\\n",
       "       count       mean  ...      75%    max count      mean       std    min   \n",
       "salida                   ...                                                    \n",
       "1       70.0  14.294286  ...  3.30100  6.685  70.0  5.087214  0.263699  4.519   \n",
       "2       70.0  16.135714  ...  4.43600  6.682  70.0  6.020600  0.253934  5.144   \n",
       "3       70.0  13.247857  ...  5.46725  8.456  70.0  5.116400  0.162068  4.745   \n",
       "\n",
       "                                        \n",
       "           25%     50%      75%    max  \n",
       "salida                                  \n",
       "1       4.9245  5.0940  5.22350  5.877  \n",
       "2       5.8775  5.9815  6.18775  6.550  \n",
       "3       5.0020  5.0915  5.22850  5.491  \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de los datos de entrenamiento\n",
    "d_train = pd.read_csv(\"dataset/seeds_dataset.csv\")\n",
    "d_train.head(5)\n",
    "d_train.groupby('salida').describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacion de dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normDataset(x, val):\n",
    "    return x/val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>salida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>0.03465</td>\n",
       "      <td>0.02040</td>\n",
       "      <td>0.05877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.03505</td>\n",
       "      <td>0.01969</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.1485</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.05714</td>\n",
       "      <td>0.03242</td>\n",
       "      <td>0.04543</td>\n",
       "      <td>0.05314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.05438</td>\n",
       "      <td>0.03201</td>\n",
       "      <td>0.01717</td>\n",
       "      <td>0.05001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.05439</td>\n",
       "      <td>0.03199</td>\n",
       "      <td>0.03986</td>\n",
       "      <td>0.04738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_1   var_2     var_3    var_4    var_5    var_6    var_7  salida\n",
       "0  0.1663  0.1546  0.008747  0.06053  0.03465  0.02040  0.05877       1\n",
       "1  0.1644  0.1525  0.008880  0.05884  0.03505  0.01969  0.05533       1\n",
       "2  0.1526  0.1485  0.008696  0.05714  0.03242  0.04543  0.05314       1\n",
       "3  0.1403  0.1416  0.008796  0.05438  0.03201  0.01717  0.05001       1\n",
       "4  0.1389  0.1402  0.008880  0.05439  0.03199  0.03986  0.04738       1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizacion\n",
    "d_train[['var_1', 'var_2','var_3','var_4','var_5','var_6','var_7']] = d_train[['var_1', 'var_2','var_3','var_4','var_5','var_6','var_7']].apply(\n",
    "    lambda x: normDataset(x,100))\n",
    "\n",
    "d_train.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste de la salida\n",
    "\n",
    "Se debe poner la salida como un vector onehot, es decir, un vector que tenga como longitud la cantidad de etiquetas posibles, y que a su vez la respuesta de cada uno solo vaya de 0 a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>pequena</th>\n",
       "      <th>mediana</th>\n",
       "      <th>grande</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.05314</td>\n",
       "      <td>0.02777</td>\n",
       "      <td>0.04471</td>\n",
       "      <td>0.05178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.05279</td>\n",
       "      <td>0.02687</td>\n",
       "      <td>0.06169</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.008335</td>\n",
       "      <td>0.05176</td>\n",
       "      <td>0.02719</td>\n",
       "      <td>0.02221</td>\n",
       "      <td>0.05132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>0.05267</td>\n",
       "      <td>0.02967</td>\n",
       "      <td>0.04421</td>\n",
       "      <td>0.05002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>0.05386</td>\n",
       "      <td>0.02911</td>\n",
       "      <td>0.03260</td>\n",
       "      <td>0.05316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_1   var_2     var_3    var_4    var_5    var_6    var_7  pequena  \\\n",
       "205  0.1182  0.1340  0.008274  0.05314  0.02777  0.04471  0.05178        0   \n",
       "206  0.1121  0.1313  0.008167  0.05279  0.02687  0.06169  0.05275        0   \n",
       "207  0.1143  0.1313  0.008335  0.05176  0.02719  0.02221  0.05132        0   \n",
       "208  0.1249  0.1346  0.008658  0.05267  0.02967  0.04421  0.05002        0   \n",
       "209  0.1270  0.1371  0.008491  0.05386  0.02911  0.03260  0.05316        0   \n",
       "\n",
       "     mediana  grande  \n",
       "205        0       1  \n",
       "206        0       1  \n",
       "207        0       1  \n",
       "208        0       1  \n",
       "209        0       1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean data\n",
    "dataset = d_train.dropna()\n",
    "\n",
    "# convert categorical 'Origin' data into one-hot data\n",
    "origin = dataset.pop('salida')\n",
    "dataset['pequena'] = (origin == 1)*1\n",
    "dataset['mediana'] = (origin == 2)*1\n",
    "dataset['grande'] = (origin == 3)*1\n",
    "\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion de los datos\n",
    "\n",
    "agrupar los datos de entrenamiento y de validacion, separar las entradas de las salida y convertir las salidas en un vector de la forma [0,0,0] a paritr del dato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_x = dataset[['var_1', 'var_2','var_3','var_4','var_5','var_6','var_7']].to_numpy()\n",
    "d_train_y = dataset[['pequena','mediana','grande']].to_numpy()\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(d_train_x, d_train_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network creation\n",
    "\n",
    "creation of neural network class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class Layer, uniquely defines the attributes and functionalities of a layer e.g. size, activation function, weights etc.\n",
    "class Layer:\n",
    "    # Initializes the basic attributes of a single layer\n",
    "    def __init__(self, size, index, activation='sigmoid'):\n",
    "        self.size = size  # defines the number of stacked neurons in the layer\n",
    "        self.activation_func = activation  # defines the activation function that each neuron in the layer uses\n",
    "        self.layer_index = index  # defines the location of layer in the network\n",
    "        self.a = 0  # defines the output of the layer after running through activation\n",
    "        self.z = 0  # defines the input of layer to the activation function\n",
    "\n",
    "    # Weight initialization is very important or the we might see vanishing/exploding gradient problem\n",
    "    # We use Glroot Initialization technique to intialize our weights and biases\n",
    "    def init_weight(self, input_shape, output_shape):\n",
    "        mean = 0\n",
    "        std = np.sqrt(2/(input_shape + output_shape))\n",
    "        self.weights = np.float32(\n",
    "            np.random.uniform(-std, std, (output_shape, input_shape)))\n",
    "        self.bias = np.float32(np.random.uniform(-std, std, (output_shape, 1)))\n",
    "\n",
    "    # return the output of layer after running the input through selected activation function\n",
    "    def activation(self, inputs):\n",
    "        self.z = np.dot(self.weights, inputs) + self.bias\n",
    "        self.a = 1/(1 + np.exp(-self.z))\n",
    "        return self.a\n",
    "\n",
    "    # provides the derivative of activation function for the current output of the layer\n",
    "    def activation_grad(self):\n",
    "        return self.a * (1 - self.a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Neural Network, defines multiple layers and runs forwad and back propogation to train the network.\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # defines the shape of Network and initializes layers\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.layers = list()\n",
    "        self.log_loss_hist = list()\n",
    "        j = 0\n",
    "        for i in shape:\n",
    "            self.layers.append(Layer(i,j))\n",
    "            j = j + 1\n",
    "    \n",
    "    # Initializes the weights and biases of our network for each layer\n",
    "    def initialize(self, X, y):\n",
    "        for i in range(len(self.layers)):\n",
    "            if i == 0:\n",
    "                self.layers[i].init_weight(X.shape[1], self.layers[i].size)\n",
    "            else:\n",
    "                self.layers[i].init_weight(self.layers[i-1].size, self.layers[i].size)\n",
    "\n",
    "    # performs forward propogation\n",
    "    def forward_propogation(self, X):\n",
    "        a = X.T\n",
    "        for layer in self.layers:\n",
    "            a = layer.activation(a)\n",
    "    \n",
    "    # calculates log logs and return the result\n",
    "    def loss(self, outputs, y):\n",
    "        lb = LabelBinarizer()\n",
    "        y_lb = lb.fit_transform(y)\n",
    "        outputs_lb = lb.transform(outputs)\n",
    "        loss = log_loss(y_lb, outputs_lb)\n",
    "        return loss\n",
    "\n",
    "    # Performs the most critical, Backpropogation to calculate delta values for each layer\n",
    "    def backpropogate(self, X, y):\n",
    "        delta = list()\n",
    "        delta_w = [0 for _ in range(len(self.layers))]\n",
    "        delta_b = [0 for _ in range(len(self.layers))]\n",
    "        error_o = (self.layers[-1].z - y.T)\n",
    "        for i in reversed(range(len(self.layers) - 1)):\n",
    "            error_i = np.multiply(self.layers[i+1].weights.T.dot(error_o), self.layers[i].activation_grad())\n",
    "            delta_w[i+1] = error_o.dot(self.layers[i].a.T)/len(y)\n",
    "            delta_b[i+1] = np.sum(error_o, axis=1, keepdims=True)/len(y)\n",
    "            error_o = error_i\n",
    "        delta_w[0] = error_o.dot(X)/len(y)\n",
    "        delta_b[0] = np.sum(error_o, axis=1, keepdims=True)/len(y)\n",
    "        return (delta_w, delta_b)\n",
    "\n",
    "    # Uses the delta values to update weights and biases\n",
    "    def update_weights_bias(self, delta_w, delta_b, lr):\n",
    "        #print(self.layers[0].bias.shape)\n",
    "        for i in range(len(self.layers)):\n",
    "            layer = self.layers[i]\n",
    "            layer.weights = layer.weights - (lr*delta_w[i])\n",
    "            layer.bias = layer.bias - (lr*delta_b[i]) \n",
    "\n",
    "    # Used to orchestrate the training of network, given a certain epoch and learning rate\n",
    "    def train(self, X, y, epochs, batch_size, lr):\n",
    "        self.initialize(X, y)\n",
    "        lb = LabelBinarizer()\n",
    "        y_lb = lb.fit_transform(y)\n",
    "        y_lb = lb.fit_transform(y)\n",
    "        for i in range(epochs):\n",
    "            low = 0\n",
    "            high = low + batch_size\n",
    "            self.log_loss_hist.append(self.loss(np.argmax(self.predict(X), axis=0), y))\n",
    "            while(low < X.shape[0]):\n",
    "                X_bat = X[low:high,:]\n",
    "                y_bat = y_lb[low:high]\n",
    "                self.forward_propogation(X_bat)\n",
    "                outputs = self.layers[-1].a\n",
    "                delta_w, delta_b = self.backpropogate(X_bat, y_bat)\n",
    "                self.update_weights_bias(delta_w, delta_b, lr)\n",
    "                low = high\n",
    "                if (low + batch_size) > X.shape[0]:\n",
    "                    high = X.shape[0]\n",
    "                else:\n",
    "                    high = low + batch_size\n",
    "\n",
    "    # Runs the input through the network and returns\n",
    "    def predict(self, X):\n",
    "        a = X.T\n",
    "        for layer in self.layers:\n",
    "            a = layer.activation(a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and training\n",
    "\n",
    "Creation of the model to predict seeds distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and its architecture\n",
    "model = NeuralNetwork((5,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model using the hyper-parameters\n",
    "model.train(x_train, y_train, 2000, 5, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(model.log_loss_hist))), model.log_loss_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation process\n",
    "\n",
    "validate the Neural Network working with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 80.95\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction on test data and measure performance\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_test_out = np.argmax(y_test, axis=1)\n",
    "y_pred_out = np.argmax(y_pred, axis=0)\n",
    "\n",
    "print(f\"Accuracy Score: {np.round(accuracy_score(y_test_out, y_pred_out)*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 2, target: 2\n",
      "predict: 1, target: 0\n",
      "predict: 2, target: 2\n",
      "predict: 0, target: 0\n",
      "predict: 1, target: 0\n",
      "predict: 0, target: 0\n",
      "predict: 1, target: 1\n",
      "predict: 1, target: 1\n",
      "predict: 1, target: 1\n",
      "predict: 1, target: 1\n"
     ]
    }
   ],
   "source": [
    "# print some data test\n",
    "for i in range(10):\n",
    "    print(f\"predict: {y_pred_out[i]}, target: {y_test_out[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
