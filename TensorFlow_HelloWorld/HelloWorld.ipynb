{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train a Simple TensorFlow Lite for Microcontrollers model\n",
    "\n",
    "This notebook demonstrates the process of training a 2.5 kB model using TensorFlow and converting it for use with TensorFlow Lite for Microcontrollers. \n",
    "\n",
    "Deep learning networks learn to model patterns in underlying data. Here, we're going to train a network to model data generated by a [sine](https://en.wikipedia.org/wiki/Sine) function. This will result in a model that can take a value, `x`, and predict its sine, `y`.\n",
    "\n",
    "The model created in this notebook is used in the [hello_world](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world) example for [TensorFlow Lite for MicroControllers](https://www.tensorflow.org/lite/microcontrollers/overview).\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure Defaults"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Define paths to model files\n",
    "import os\n",
    "MODELS_DIR = 'models/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Environment\n",
    "\n",
    "Install Dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "! pip3 install tensorflow"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/0b/3d/fdb2b6065cf3570115dbd5bc14fd99afe2080b298ac64246a2fc4df6e2dc/tensorflow-2.5.0-cp38-cp38-macosx_10_11_x86_64.whl\n",
      "Collecting tensorboard~=2.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a0/20/a59a30c32330e4ff704faa4273b251db042d495e0c367bcdf045c6fe26e9/tensorboard-2.6.0-py3-none-any.whl\n",
      "Collecting astunparse~=1.6.3 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n",
      "Collecting opt-einsum~=3.3.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl\n",
      "Collecting gast==0.4.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Collecting absl-py~=0.10 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/23/47/835652c7e19530973c73c65e652fc53bd05725d5a7cf9bb8706777869c1e/absl_py-0.13.0-py3-none-any.whl\n",
      "Collecting keras-preprocessing~=1.1.2 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Collecting grpcio~=1.34.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/5a/1499769d966bf079ccb17f5a3c8d52be5656d06e1e3b6529f702be801523/grpcio-1.34.1-cp38-cp38-macosx_10_10_x86_64.whl\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl\n",
      "Collecting numpy~=1.19.2 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a6/b7/c0594c698c7149bfe738724ab9ab3722dca3a4a43823468fe9481abe4016/numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Collecting wheel~=0.35 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/63/39d04c74222770ed1589c0eaba06c05891801219272420b40311cd60c880/wheel-0.36.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six~=1.15.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting protobuf>=3.9.2 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/af/f4/0f7ea83bc253f296ed7159c29e000a07f0c82fccd3128e38b7487773cf41/protobuf-3.17.3-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Collecting typing-extensions~=3.7.4 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Collecting termcolor~=1.1.0 (from tensorflow)\n",
      "Collecting flatbuffers~=1.12.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl\n",
      "Collecting wrapt~=1.12.1 (from tensorflow)\n",
      "Collecting keras-nightly~=2.5.0.dev (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/aa/e7/53bc896aa4e11a87aac10a625c676b3a3d57d1c8d9929e4809d31fa0b7d5/keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl\n",
      "Collecting google-pasta~=0.2 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl\n",
      "Collecting h5py~=3.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/f1/86/d5009c3cf1fd93b3ce9ad17c83c1da76f857cf330a32013caa063809f210/h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/c1/499e600ba0c618b451cd9c425ae1c177249940a2086316552fee7d86c954/tensorboard_plugin_wit-1.8.0-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (41.2.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/35/bb/694d851e2c0776a422d43d579b82b7cc065da248d557f37595563824b1c9/google_auth-1.34.0-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/92/96/144f70b972a9c0eabbd4391ef93ccd49d0f2747f4f6a2a2738e99e5adc65/requests-2.26.0-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/bd/24/11c3ea5a7e866bf2d97f0501d0b4b1c9bbeade102bb4b588f0d2919a5212/Werkzeug-2.0.1-py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/6e/33/1ae0f71395e618d6140fbbc9587cc3156591f748226075e0f7d6f9176522/Markdown-3.3.4-py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/d9/df4019fc28b3aed8218e1bfca38158b90b70a3583c15f568ca669564dc24/google_auth_oauthlib-0.4.5-py2.py3-none-any.whl\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3e/48/dd135dbb3cf16bfb923720163493cab70e7336db4b5f3103d49efa730404/tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\" (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/93/0c0f002031f18b53af7a6166103c02b9c0667be528944137cc954ec921b3/rsa-4.7.2-py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/bf/28/c4f5796c67ad06bb91d98d543a5e01805c1ff065e08871f78e52d2a331ad/cachetools-4.2.2-py3-none-any.whl\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/5f/64/43575537846896abac0b15c3e5ac678d787a4021e906703f1766bfb8ea11/urllib3-1.26.6-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/1b/0a0dece0e8aa492a6ec9e4ad2fe366b511558cdc73fd3abc82ba7348e875/certifi-2021.5.30-py2.py3-none-any.whl\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\" (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/33/53/b7f6126a2b9fd878b025fe3c40266cfaad696f312165008ce045bffa3fe7/charset_normalizer-2.0.4-py3-none-any.whl\n",
      "Collecting idna<4,>=2.5; python_version >= \"3\" (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/77/ff688d1504cdc4db2a938e2b7b9adee5dd52e34efbd2431051efc9984de9/idna-3.2-py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/5d/9dd1c29e5a786525f6342f6c1d812ed2e37edc653ad297048c1668988053/oauthlib-3.1.1-py2.py3-none-any.whl\n",
      "\u001b[31mERROR: botocore 1.18.13 requires python-dateutil<3.0.0,>=2.1, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: botocore 1.18.13 has requirement urllib3<1.26,>=1.20; python_version != \"3.4\", but you'll have urllib3 1.26.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: grpcio, tensorboard-plugin-wit, wheel, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, protobuf, absl-py, numpy, urllib3, certifi, charset-normalizer, idna, requests, werkzeug, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, tensorboard, astunparse, opt-einsum, gast, keras-preprocessing, tensorflow-estimator, typing-extensions, termcolor, flatbuffers, wrapt, keras-nightly, google-pasta, h5py, tensorflow\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/Library/Python/3.8'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[link text](https://)Import Dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# TensorFlow is an open source machine learning library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras is TensorFlow's high-level API for deep learning\n",
    "from tensorflow import keras\n",
    "# Numpy is a math library\n",
    "import numpy as np\n",
    "# Pandas is a data manipulation library \n",
    "import pandas as pd\n",
    "# Matplotlib is a graphing library\n",
    "import matplotlib.pyplot as plt\n",
    "# Math is Python's math library\n",
    "import math\n",
    "\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Generate Data\n",
    "\n",
    "The code in the following cell will generate a set of random `x` values, calculate their sine values, and display them on a graph."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Number of sample datapoints\n",
    "SAMPLES = 1000\n",
    "\n",
    "# Generate a uniformly distributed set of random numbers in the range from\n",
    "# 0 to 2π, which covers a complete sine wave oscillation\n",
    "x_values = np.random.uniform(\n",
    "    low=0, high=2*math.pi, size=SAMPLES).astype(np.float32)\n",
    "\n",
    "# Shuffle the values to guarantee they're not in order\n",
    "np.random.shuffle(x_values)\n",
    "\n",
    "# Calculate the corresponding sine values\n",
    "y_values = (np.sin(x_values)*x_values).astype(np.float32)\n",
    "\n",
    "# Plot our data. The 'b.' argument tells the library to print blue dots.\n",
    "plt.plot(x_values, y_values, 'b.')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Add Noise\n",
    "Since it was generated directly by the sine function, our data fits a nice, smooth curve.\n",
    "\n",
    "However, machine learning models are good at extracting underlying meaning from messy, real world data. To demonstrate this, we can add some noise to our data to approximate something more life-like.\n",
    "\n",
    "In the following cell, we'll add some random noise to each value, then draw a new graph:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Add a small random number to each y value\n",
    "y_values += 0.1 * np.random.randn(*y_values.shape)\n",
    "\n",
    "# Plot our data\n",
    "plt.plot(x_values, y_values, 'b.')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Split the Data\n",
    "We now have a noisy dataset that approximates real world data. We'll be using this to train our model.\n",
    "\n",
    "To evaluate the accuracy of the model we train, we'll need to compare its predictions to real data and check how well they match up. This evaluation happens during training (where it is referred to as validation) and after training (referred to as testing) It's important in both cases that we use fresh data that was not already used to train the model.\n",
    "\n",
    "The data is split as follows:\n",
    "  1. Training: 60%\n",
    "  2. Validation: 20%\n",
    "  3. Testing: 20% \n",
    "\n",
    "The following code will split our data and then plots each set as a different color:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
    "# will be used for validation. Calculate the indices of each section.\n",
    "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
    "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
    "\n",
    "# Use np.split to chop our data into three parts.\n",
    "# The second argument to np.split is an array of indices where the data will be\n",
    "# split. We provide two indices, so the data will be divided into three chunks.\n",
    "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "# Double check that our splits add up correctly\n",
    "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
    "\n",
    "# Plot the data in each partition in different colors:\n",
    "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
    "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
    "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Design the Model\n",
    "We're going to build a simple neural network model that will take an input value (in this case, `x`) and use it to predict a numeric output value (the sine of `x`). This type of problem is called a _regression_. It will use _layers_ of _neurons_ to attempt to learn any patterns underlying the training data, so it can make predictions.\n",
    "\n",
    "To begin with, we'll define two layers. The first layer takes a single input (our `x` value) and runs it through 8 neurons. Based on this input, each neuron will become _activated_ to a certain degree based on its internal state (its _weight_ and _bias_ values). A neuron's degree of activation is expressed as a number.\n",
    "\n",
    "The activation numbers from our first layer will be fed as inputs to our second layer, which is a single neuron. It will apply its own weights and bias to these inputs and calculate its own activation, which will be output as our `y` value.\n",
    "\n",
    "**Note:** To learn more about how neural networks function, you can explore the [Learn TensorFlow](https://codelabs.developers.google.com/codelabs/tensorflow-lab1-helloworld) codelabs.\n",
    "\n",
    "The code in the following cell defines our model using [Keras](https://www.tensorflow.org/guide/keras), TensorFlow's high-level API for creating deep learning networks. Once the network is defined, we _compile_ it, specifying parameters that determine how it will be trained:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We'll use Keras to create a simple model architecture\n",
    "model_1 = tf.keras.Sequential()\n",
    "\n",
    "# First layer takes a scalar input and feeds it through 8 \"neurons\". The\n",
    "# neurons decide whether to activate based on the 'relu' activation function.\n",
    "model_1.add(keras.layers.Dense(8, activation='relu', input_shape=(1,)))\n",
    "\n",
    "# Final layer is a single neuron, since we want to output a single value\n",
    "model_1.add(keras.layers.Dense(1))\n",
    "\n",
    "# Compile the model using the standard 'adam' optimizer and the mean squared error or 'mse' loss function for regression.\n",
    "model_1.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Train the Model\n",
    "Once we've defined the model, we can use our data to _train_ it. Training involves passing an `x` value into the neural network, checking how far the network's output deviates from the expected `y` value, and adjusting the neurons' weights and biases so that the output is more likely to be correct the next time.\n",
    "\n",
    "Training runs this process on the full dataset multiple times, and each full run-through is known as an _epoch_. The number of epochs to run during training is a parameter we can set.\n",
    "\n",
    "During each epoch, data is run through the network in multiple _batches_. Each batch, several pieces of data are passed into the network, producing output values. These outputs' correctness is measured in aggregate and the network's weights and biases are adjusted accordingly, once per batch. The _batch size_ is also a parameter we can set.\n",
    "\n",
    "The code in the following cell uses the `x` and `y` values from our training data to train the model. It runs for 500 _epochs_, with 64 pieces of data in each _batch_. We also pass in some data for _validation_. As you will see when you run the cell, training can take a while to complete:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train the model on our training data while validating on our validation set\n",
    "history_1 = model_1.fit(x_train, y_train, epochs=500, batch_size=64,\n",
    "                        validation_data=(x_validate, y_validate))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Plot Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Loss (or Mean Squared Error)**\n",
    "\n",
    "During training, the model's performance is constantly being measured against both our training data and the validation data that we set aside earlier. Training produces a log of data that tells us how the model's performance changed over the course of the training process.\n",
    "\n",
    "The following cells will display some of that data in a graphical form:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Draw a graph of the loss, which is the distance between\n",
    "# the predicted and actual values during training and validation.\n",
    "train_loss = history_1.history['loss']\n",
    "val_loss = history_1.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The graph shows the _loss_ (or the difference between the model's predictions and the actual data) for each epoch. There are several ways to calculate loss, and the method we have used is _mean squared error_. There is a distinct loss value given for the training and the validation data.\n",
    "\n",
    "As we can see, the amount of loss rapidly decreases over the first 25 epochs, before flattening out. This means that the model is improving and producing more accurate predictions!\n",
    "\n",
    "Our goal is to stop training when either the model is no longer improving, or when the _training loss_ is less than the _validation loss_, which would mean that the model has learned to predict the training data so well that it can no longer generalize to new data.\n",
    "\n",
    "To make the flatter part of the graph more readable, let's skip the first 50 epochs:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Exclude the first few epochs so the graph is easier to read\n",
    "SKIP = 50\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the plot, we can see that loss continues to reduce until around 200 epochs, at which point it is mostly stable. This means that there's no need to train our network beyond 200 epochs.\n",
    "\n",
    "However, we can also see that the lowest loss value is still around 0.155. This means that our network's predictions are off by an average of ~15%. In addition, the validation loss values jump around a lot, and is sometimes even higher.\n",
    "\n",
    "**2. Mean Absolute Error**\n",
    "\n",
    "To gain more insight into our model's performance we can plot some more data. This time, we'll plot the _mean absolute error_, which is another way of measuring how far the network's predictions are from the actual numbers:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.clf()\n",
    "\n",
    "# Draw a graph of mean absolute error, which is another way of\n",
    "# measuring the amount of error in the prediction.\n",
    "train_mae = history_1.history['mae']\n",
    "val_mae = history_1.history['val_mae']\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This graph of _mean absolute error_ tells another story. We can see that training data shows consistently lower error than validation data, which means that the network may have _overfit_, or learned the training data so rigidly that it can't make effective predictions about new data.\n",
    "\n",
    "In addition, the mean absolute error values are quite high, ~0.305 at best, which means some of the model's predictions are at least 30% off. A 30% error means we are very far from accurately modelling the sine wave function.\n",
    "\n",
    "**3. Actual vs Predicted Outputs**\n",
    "\n",
    "To get more insight into what is happening, let's check its predictions against the test dataset we set aside earlier:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate and print the loss on our test dataset\n",
    "test_loss, test_mae = model_1.evaluate(x_test, y_test)\n",
    "\n",
    "# Make predictions based on our test dataset\n",
    "y_test_pred = model_1.predict(x_test)\n",
    "\n",
    "# Graph the predictions against the actual values\n",
    "plt.clf()\n",
    "plt.title('Comparison of predictions and actual values')\n",
    "plt.plot(x_test, y_test, 'b.', label='Actual values')\n",
    "plt.plot(x_test, y_test_pred, 'r.', label='TF predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oh dear! The graph makes it clear that our network has learned to approximate the sine function in a very limited way.\n",
    "\n",
    "The rigidity of this fit suggests that the model does not have enough capacity to learn the full complexity of the sine wave function, so it's only able to approximate it in an overly simplistic way. By making our model bigger, we should be able to improve its performance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training a Larger Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Design the Model\n",
    "To make our model bigger, let's add an additional layer of neurons. The following cell redefines our model in the same way as earlier, but with 16 neurons in the first layer and an additional layer of 16 neurons in the middle:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
    "# neurons decide whether to activate based on the 'relu' activation function.\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(1,)))\n",
    "\n",
    "# The new second and third layer will help the network learn more complex representations\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "\n",
    "# Final layer is a single neuron, since we want to output a single value\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# Compile the model using the standard 'adam' optimizer and the mean squared error or 'mse' loss function for regression.\n",
    "model.compile(optimizer='adam', loss=\"mse\", metrics=[\"mae\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Train the Model ###\n",
    "\n",
    "We'll now train and save the new model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=500, batch_size=64,\n",
    "                    validation_data=(x_validate, y_validate))\n",
    "\n",
    "# Save the model to disk\n",
    "model.save(MODEL_TF)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Plot Metrics\n",
    "Each training epoch, the model prints out its loss and mean absolute error for training and validation. You can read this in the output above (note that your exact numbers may differ): \n",
    "\n",
    "```\n",
    "Epoch 500/500\n",
    "10/10 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.0882 - val_loss: 0.0115 - val_mae: 0.0865\n",
    "```\n",
    "\n",
    "You can see that we've already got a huge improvement - validation loss has dropped from 0.15 to 0.01, and validation MAE has dropped from 0.33 to 0.08.\n",
    "\n",
    "The following cell will print the same graphs we used to evaluate our original model, but showing our new training history:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Draw a graph of the loss, which is the distance between\n",
    "# the predicted and actual values during training and validation.\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Exclude the first few epochs so the graph is easier to read\n",
    "SKIP = 100\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Draw a graph of mean absolute error, which is another way of\n",
    "# measuring the amount of error in the prediction.\n",
    "train_mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great results! From these graphs, we can see several exciting things:\n",
    "\n",
    "*   The overall loss and MAE are much better than our previous network\n",
    "*   Metrics are better for validation than training, which means the network is not overfitting\n",
    "\n",
    "The reason the metrics for validation are better than those for training is that validation metrics are calculated at the end of each epoch, while training metrics are calculated throughout the epoch, so validation happens on a model that has been trained slightly longer.\n",
    "\n",
    "This all means our network seems to be performing well! To confirm, let's check its predictions against the test dataset we set aside earlier:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate and print the loss on our test dataset\n",
    "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Make predictions based on our test dataset\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "# Graph the predictions against the actual values\n",
    "plt.clf()\n",
    "plt.title('Comparison of predictions and actual values')\n",
    "plt.plot(x_test, y_test, 'b.', label='Actual values')\n",
    "plt.plot(x_test, y_test_pred, 'r.', label='TF predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Much better! The evaluation metrics we printed show that the model has a low loss and MAE on the test data, and the predictions line up visually with our data fairly well.\n",
    "\n",
    "The model isn't perfect; its predictions don't form a smooth sine curve. For instance, the line is almost straight when `x` is between 4.2 and 5.2. If we wanted to go further, we could try further increasing the capacity of the model, perhaps using some techniques to defend from overfitting.\n",
    "\n",
    "However, an important part of machine learning is *knowing when to stop*. This model is good enough for our use case - which is to make some LEDs blink in a pleasing pattern.\n",
    "\n",
    "## Generate a TensorFlow Lite Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Generate Models with or without Quantization\n",
    "We now have an acceptably accurate model. We'll use the [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert) to convert the model into a special, space-efficient format for use on memory-constrained devices.\n",
    "\n",
    "Since this model is going to be deployed on a microcontroller, we want it to be as tiny as possible! One technique for reducing the size of a model is called [quantization](https://www.tensorflow.org/lite/performance/post_training_quantization). It reduces the precision of the model's weights, and possibly the activations (output of each layer) as well, which saves memory, often without much impact on accuracy. Quantized models also run faster, since the calculations required are simpler.\n",
    "\n",
    "In the following cell, we'll convert the model twice: once with quantization, once without."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset():\n",
    "  for i in range(500):\n",
    "    yield([x_train[i].reshape(1, 1)])\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Compare Model Performance\n",
    "\n",
    "To prove these models are accurate even after conversion and quantization, we'll compare their predictions and loss on our test dataset.\n",
    "\n",
    "**Helper functions**\n",
    "\n",
    "We define the `predict` (for predictions) and `evaluate` (for loss) functions for TFLite models. *Note: These are already included in a TF model, but not in  a TFLite model.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predict_tflite(tflite_model, x_test):\n",
    "  # Prepare the test data\n",
    "  x_test_ = x_test.copy()\n",
    "  x_test_ = x_test_.reshape((x_test.size, 1))\n",
    "  x_test_ = x_test_.astype(np.float32)\n",
    "\n",
    "  # Initialize the TFLite interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  # If required, quantize the input layer (from float to integer)\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  if (input_scale, input_zero_point) != (0.0, 0):\n",
    "    x_test_ = x_test_ / input_scale + input_zero_point\n",
    "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
    "  \n",
    "  # Invoke the interpreter\n",
    "  y_pred = np.empty(x_test_.size, dtype=output_details[\"dtype\"])\n",
    "  for i in range(len(x_test_)):\n",
    "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "    interpreter.invoke()\n",
    "    y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "  \n",
    "  # If required, dequantized the output layer (from integer to float)\n",
    "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "  if (output_scale, output_zero_point) != (0.0, 0):\n",
    "    y_pred = y_pred.astype(np.float32)\n",
    "    y_pred = (y_pred - output_zero_point) * output_scale\n",
    "\n",
    "  return y_pred\n",
    "\n",
    "def evaluate_tflite(tflite_model, x_test, y_true):\n",
    "  global model\n",
    "  y_pred = predict_tflite(tflite_model, x_test)\n",
    "  loss_function = tf.keras.losses.get(model.loss)\n",
    "  loss = loss_function(y_true, y_pred).numpy()\n",
    "  return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "** *italicized text*1. Predictions**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate predictions\n",
    "y_test_pred_tf = model.predict(x_test)\n",
    "y_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, x_test)\n",
    "y_test_pred_tflite = predict_tflite(model_tflite, x_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Compare predictions\n",
    "plt.clf()\n",
    "plt.title('Comparison of various models against actual values')\n",
    "plt.plot(x_test, y_test, 'bo', label='Actual values')\n",
    "plt.plot(x_test, y_test_pred_tf, 'ro', label='TF predictions')\n",
    "plt.plot(x_test, y_test_pred_no_quant_tflite, 'bx', label='TFLite predictions')\n",
    "plt.plot(x_test, y_test_pred_tflite, 'gx', label='TFLite quantized predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Loss (MSE/Mean Squared Error)**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate loss\n",
    "loss_tf, _ = model.evaluate(x_test, y_test, verbose=0)\n",
    "loss_no_quant_tflite = evaluate_tflite(model_no_quant_tflite, x_test, y_test)\n",
    "loss_tflite = evaluate_tflite(model_tflite, x_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Compare loss\n",
    "df = pd.DataFrame.from_records(\n",
    "    [[\"TensorFlow\", loss_tf],\n",
    "     [\"TensorFlow Lite\", loss_no_quant_tflite],\n",
    "     [\"TensorFlow Lite Quantized\", loss_tflite]],\n",
    "     columns = [\"Model\", \"Loss/MSE\"], index=\"Model\").round(4)\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Size**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate size\n",
    "size_tf = os.path.getsize(MODEL_TF)\n",
    "size_no_quant_tflite = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
    "size_tflite = os.path.getsize(MODEL_TFLITE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Compare size\n",
    "pd.DataFrame.from_records(\n",
    "    [[\"TensorFlow\", f\"{size_tf} bytes\", \"\"],\n",
    "     [\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \", f\"(reduced by {size_tf - size_no_quant_tflite} bytes)\"],\n",
    "     [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\", f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
    "     columns = [\"Model\", \"Size\", \"\"], index=\"Model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Summary**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see from the predictions (graph) and loss (table) that the original TF model, the TFLite model, and the quantized TFLite model are all close enough to be indistinguishable - even though they differ in size (table). This implies that the quantized (smallest) model is ready to use!\n",
    "\n",
    "*Note: The quantized (integer) TFLite model is just 300 bytes smaller than the original (float) TFLite model - a tiny reduction in size! This is because the model is already so small that quantization has little effect. Complex models with more weights, can have upto a 4x reduction in size!*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate a TensorFlow Lite for Microcontrollers Model\n",
    "Convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Install xxd if it is not available\n",
    "!apt-get update && apt-get -qq install xxd\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "# Update variable names\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deploy to a Microcontroller\n",
    "\n",
    "Follow the instructions in the [hello_world](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world) README.md for [TensorFlow Lite for MicroControllers](https://www.tensorflow.org/lite/microcontrollers/overview) to deploy this model on a specific microcontroller.\n",
    "\n",
    "**Reference Model:** If you have not modified this notebook, you can follow the instructions as is, to deploy the model. Refer to the [`hello_world/train/models`](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/train/models) directory to access the models generated in this notebook.\n",
    "\n",
    "**New Model:** If you have generated a new model, then update the values assigned to the variables defined in [`hello_world/model.cc`](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/model.cc) with values displayed after running the following cell."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print the C source file\n",
    "!cat {MODEL_TFLITE_MICRO}"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}